model_info stores best network.

please note that training plateaued ~64th best net in the first run, 69th net consistently lost by a small amount to the 64th net.

learning rate for 64th net was manually lowered from 0.001 to 0.0003 (using https://stackoverflow.com/questions/47523841/using-keras-to-load-model-and-assign-new-values-to-its-parameters)

all nets from 65 onward were deleted and training restarted.

74 and 78 were compared



93rd network could barely beat the 74th network. Probably needs a lowering of learning rate again.

93rd model renamed to 0th model in order to save space while putting to gdrive.

Learning rate was manually lowered once again to 0.0001.

20th model, new best, was lowered to 1e-5 learning rate. Then it was renamed to the 0th model yet again.

Then the 21st model after that was renamed to 0th again.


New network created: using 7 shared blocks of mlp resnet, 1024 neurons, learning rate 0.01 to start.
also lowered the loss weight of the value head to 0.1 to reduce overfitting, since we're using all training data.


19th network of resnet surpassed the old best network (which used 6 shared blocks of 512 neurons each).


43rd was last strongest net, some reason 44th lost 250:150.	

After training overnight, 57th network lost to the 43rd network (179:221 and another round 176:224, pretty big).

59th network is clone of 43rd network with lowered learning rate to 0.003.

63rd new model was renamed to 0th model again.

For some reason the network got weaker; 17th model was about equal to the new 0th model. Must have forgotten something along the way.

Some tests by hand:

17 to 0:
 best 200 old 200
draws 76

12 to 0:
 best 217.5 old 182.5
draws 81

12 to 8:
 best 174 old 226
draws 86

8 to 10:
 best 182.5 old 217.5
draws 97

10 to 11:
 best 191 old 209
draws 88

11 to 12:
 best 201 old 199
draws 92

11 to 8:
 best 208.5 old 191.5
draws 85

11 to 5:
 best 205 old 195
draws 88

10 to 5:
 best 205 old 195
draws 82

10 to 12:
 best 181.5 old 218.5
draws 129

12 to 8:
 best 194 old 206
draws 92

11 to 14:
 best 200 old 200
draws 94

11 to 0:
 best 185.5 old 214.5
draws 83

11 to 0:
 best 196 old 204
draws 78

12 to 0:
 best 223.5 old 176.5
draws 101

8 to 0:
 best 220 old 180
draws 96

17 to 0:
 best 208.5 old 191.5
draws 101

8 to 10:
 best 214 old 186
draws 104

10 to 0:
 best 198 old 202
draws 92

8 to 1:
 best 200.5 old 199.5
draws 107

8 to 3:
 best 224 old 176
draws 92

Result:
Rank Name   Elo    +    - games score oppo. draws
   1 p8      10   13   13  2400   52%     0   23%
   2 p12      7   12   12  2400   51%     1   24%
   3 p14      0   31   31   400   50%     0   24%
   4 p11      0   12   12  2800   50%    -1   22%
   5 p17      0   22   22   800   51%    -6   22%
   6 p10     -3   12   12  2400   49%     2   25%
   7 p0      -6   11   11  3200   48%     3   22%
   8 p5      -8   22   22   800   49%    -1   21%

Renaming 8th model to the best and trying again, lowered learning rate to 0.001.

Increased gating threshold to 210/400.

Rank Name   Elo    +    - games score oppo. draws
   1 p13     25   14   14  2000   55%    -3   24%
   2 p8      16   11   11  2800   53%     0   29%
   3 p9      10   13   13  2000   48%    20   29%
   4 p4      -2   15   15  1600   49%     2   26%
   5 p0     -49   18   18  1200   39%    13   21%

Renamed 13th model to 0th model for release purposes.

Trained another 20 nets but none were stronger than the 0th. Lowering learning rate yet again to 0.0003.

Trained 18 more nets; result:

Rank Name   Elo    +    - games score oppo. draws
   1 p13     30   14   14  2000   57%    -9   26%
   2 p11     19   17   17  1200   53%     5   30%
   3 p7      17   15   15  1590   53%     1   34%
   4 p6     -13   15   15  1590   48%    -2   32%
   5 p5     -20   17   17  1200   51%   -26   33%
   6 p0     -33   11   11  2800   43%     6   27%

(Mistyped the p6 vs p7 duel by 10 games, but it doesn't really matter)

Renamed 13th model to 0th again, lowered learning rate to 0.0001.

None of next 16 models could match up. Lowered learning rate to 0.00003.

Still couldn't stack up over the next 13 models. New architecture time!

lowered 16th learning rate to 0.003 and continued

lowered 22nd learning rate to 0.001 and continued

50th model still couldn't beat 0th, lowered learning rate of 29th model to 0.0003 (it had higher winrate)

42nd model barely beat the 0th after lowering, but significantly slower

Tune back architecture to 10b 1024 neurons/layer, changed value head wt to 1, train on window of 416k games (positions selected randomly), +73 elo, renamed 27th model to best_0 again.
Slightly slower but the elo gain is worth it